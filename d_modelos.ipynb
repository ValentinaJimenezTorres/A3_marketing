{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMUDhFS4Z4HVk7O66uUTEKK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["############################################\n","### 1. INSTALACION DE LIBRERIAS\n","############################################\n","\n","!pip install lightfm\n","!pip install --quiet optuna\n","\n","import pandas as pd\n","import numpy as np\n","\n","from sklearn import neighbors\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import train_test_split\n","\n","from lightfm import LightFM\n","from lightfm.data import Dataset\n","from lightfm.evaluation import auc_score\n","\n","import optuna\n","\n","import sqlite3 as sql\n","import joblib\n","\n","from ipywidgets import interact\n","\n","import time\n","\n","from google.colab import drive\n","import sys\n","import os\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YxLyCMDirlhe","executionInfo":{"status":"ok","timestamp":1747091455385,"user_tz":300,"elapsed":10285,"user":{"displayName":"DAVID GUILLERMO DIAZ RODRIGUEZ","userId":"08446243037927248072"}},"outputId":"8df5053e-5035-4445-8e31-1b2ee81ecb18"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: lightfm in /usr/local/lib/python3.11/dist-packages (1.17)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from lightfm) (2.0.2)\n","Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.11/dist-packages (from lightfm) (1.15.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from lightfm) (2.32.3)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from lightfm) (1.6.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->lightfm) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->lightfm) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->lightfm) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->lightfm) (2025.4.26)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->lightfm) (1.5.0)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->lightfm) (3.6.0)\n"]}]},{"cell_type":"code","source":["############################################\n","### 2. CARGAR DATOS PREPROCESADOS\n","############################################\n","\n","# Montar Google Drive\n","drive.mount('/content/drive')\n","\n","# Definir rutas\n","base_path = '/content/drive/My Drive/cod/A3_marketing'\n","data_path = os.path.join(base_path, 'data')\n","output_path = os.path.join(base_path, 'salidas')\n","\n","# Asegurarse de que las carpetas existen\n","os.makedirs(data_path, exist_ok=True)\n","os.makedirs(output_path, exist_ok=True)\n","\n","# Cargar el DataFrame escalado\n","df_scaled = joblib.load(os.path.join(output_path, 'df_scaled.joblib'))\n","\n","# Conectarse a la base de datos SQLite\n","db_path = os.path.join(data_path, 'db_movies_c')  # Asegúrate de que este archivo exista y sea una base SQLite válida\n","con = sql.connect(db_path)\n","\n","# Cargar tabla desde la base de datos\n","movies = pd.read_sql('SELECT * FROM tabla_final', con)\n","\n","# Mostrar una vista previa\n","print(movies.head())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":425},"id":"bJ0hK2fLyeaK","executionInfo":{"status":"error","timestamp":1747091986466,"user_tz":300,"elapsed":963,"user":{"displayName":"DAVID GUILLERMO DIAZ RODRIGUEZ","userId":"08446243037927248072"}},"outputId":"2e56412e-1eb4-48e2-9b07-a836e7b97c0d"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]},{"output_type":"error","ename":"DatabaseError","evalue":"Execution failed on sql 'SELECT * FROM tabla_final': no such table: tabla_final","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, sql, params)\u001b[0m\n\u001b[1;32m   2673\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2674\u001b[0;31m             \u001b[0mcur\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2675\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcur\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOperationalError\u001b[0m: no such table: tabla_final","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mDatabaseError\u001b[0m                             Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-01a9ee47e90f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;31m# Cargar tabla desde la base de datos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mmovies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_sql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'SELECT * FROM tabla_final'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# Mostrar una vista previa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mread_sql\u001b[0;34m(sql, con, index_col, coerce_float, params, parse_dates, columns, chunksize, dtype_backend, dtype)\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mpandasSQL_builder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcon\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpandas_sql\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpandas_sql\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSQLiteDatabase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 706\u001b[0;31m             return pandas_sql.read_query(\n\u001b[0m\u001b[1;32m    707\u001b[0m                 \u001b[0msql\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m                 \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mread_query\u001b[0;34m(self, sql, index_col, coerce_float, parse_dates, params, chunksize, dtype, dtype_backend)\u001b[0m\n\u001b[1;32m   2736\u001b[0m         \u001b[0mdtype_backend\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDtypeBackend\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mLiteral\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"numpy\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"numpy\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2737\u001b[0m     ) -> DataFrame | Iterator[DataFrame]:\n\u001b[0;32m-> 2738\u001b[0;31m         \u001b[0mcursor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2739\u001b[0m         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcol_desc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcol_desc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescription\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, sql, params)\u001b[0m\n\u001b[1;32m   2684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2685\u001b[0m             \u001b[0mex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDatabaseError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Execution failed on sql '{sql}': {exc}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2686\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mex\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2688\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mDatabaseError\u001b[0m: Execution failed on sql 'SELECT * FROM tabla_final': no such table: tabla_final"]}]},{"cell_type":"code","source":["#######################################################################\n","#### 3 Sistema de recomendación basado en contenido KNN #################\n","#### Con base en todo lo visto por el usuario #######################\n","#######################################################################\n","\n","# Seleccionar usuario para recomendaciones\n","usuarios = pd.read_sql('SELECT DISTINCT userId as user_id FROM ratings', con)\n","user_id = 1  # Ejemplo manual\n","\n","def recomendar(user_id=1):\n","\n","    # Seleccionar solo los ratings del usuario seleccionado\n","    ratings = pd.read_sql('SELECT * FROM ratings WHERE userId = :user', con, params={'user': user_id})\n","    l_movies_r = ratings['movieId'].to_numpy()\n","\n","    # Agregar columnas necesarias para mostrar luego\n","    df_scaled[['movieId', 'title']] = movies[['movieId', 'title']]\n","\n","    # Filtrar películas calificadas por el usuario\n","    movies_r = df_scaled[df_scaled['movieId'].isin(l_movies_r)]\n","\n","    # Eliminar columnas no numéricas\n","    movies_r = movies_r.drop(columns=['movieId', 'title'])\n","    movies_r[\"indice\"] = 1\n","    centroide = movies_r.groupby(\"indice\").mean()\n","\n","    # Filtrar películas no vistas\n","    movies_nr = df_scaled[~df_scaled['movieId'].isin(l_movies_r)]\n","    movies_nr_simple = movies_nr.drop(columns=['movieId', 'title'])\n","\n","    # Modelo KNN\n","    model = neighbors.NearestNeighbors(n_neighbors=11, metric='cosine')\n","    model.fit(movies_nr_simple)\n","    dist, idlist = model.kneighbors(centroide)\n","\n","    ids = idlist[0]\n","    recomend_m = movies_nr.iloc[ids][['title', 'movieId']]\n","    leidos = movies[movies['movieId'].isin(l_movies_r)][['title', 'movieId']]\n","\n","    return recomend_m\n","\n","# Ejemplo de recomendación para el usuario con ID = 1\n","recomendar(1)\n","interact(recomendar)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":211},"id":"E6-mU0J3rukI","executionInfo":{"status":"error","timestamp":1747090271396,"user_tz":300,"elapsed":31,"user":{"displayName":"DAVID GUILLERMO DIAZ RODRIGUEZ","userId":"08446243037927248072"}},"outputId":"2d1e1a0a-08ef-46db-db53-680da9973559"},"execution_count":null,"outputs":[{"output_type":"error","ename":"OperationalError","evalue":"unable to open database file","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-34c4c1de5259>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Conexión a la base de datos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mcon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/db_movies_c'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Se corrigió el nombre de la base de datos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Cargar el DataFrame escalado\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOperationalError\u001b[0m: unable to open database file"]}]},{"cell_type":"code","source":["#######################################################################\n","#### 4 Sistema de recomendación con LightFM ##########################\n","#######################################################################\n","\n","# Cargar data\n","ratings = pd.read_sql('SELECT * FROM ratings', con)\n","\n","# Crear dataset\n","dataset_train = Dataset()\n","dataset_test = Dataset()\n","\n","all_unique_users = ratings['userId'].unique()\n","all_unique_items = ratings['movieId'].unique()\n","\n","dataset_train.fit(users=all_unique_users, items=all_unique_items)\n","dataset_test.fit(users=all_unique_users, items=all_unique_items)\n","\n","# Separar en train y test\n","train_df, test_df = train_test_split(ratings, test_size=0.2, random_state=42)\n","\n","# Crear interacciones\n","train_interactions_list = [(row['userId'], row['movieId'], row['rating']) for index, row in train_df.iterrows()]\n","train_interactions, train_weights = dataset_train.build_interactions(train_interactions_list)\n","\n","test_interactions_list = [(row['userId'], row['movieId'], row['rating']) for index, row in test_df.iterrows()]\n","test_interactions, test_weights = dataset_test.build_interactions(test_interactions_list)\n","\n","# Entrenamiento del modelo LightFM\n","model = LightFM(loss='logistic', random_state=42)\n","model.fit(train_interactions, epochs=20, verbose=True, sample_weight=train_weights)\n","\n","# Evaluación AUC\n","train_auc = auc_score(model, train_interactions).mean()\n","test_auc = auc_score(model, test_interactions).mean()\n","print(f'AUC: train {train_auc:.2f}, test {test_auc:.2f}')"],"metadata":{"id":"me6XhC3pr7iu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#######################################################################\n","#### 5 Ajuste de hiperparámetros con Optuna ###########################\n","#######################################################################\n","\n","def objective(trial):\n","    n_components = trial.suggest_int('no_components', 10, 100)\n","    learning_rate = trial.suggest_float('learning_rate', 0.001, 0.1, log=True)\n","    loss = trial.suggest_categorical('loss', ['logistic', 'bpr', 'warp'])\n","    epochs = trial.suggest_int('epochs', 10, 50)\n","\n","    model = LightFM(\n","        no_components=n_components,\n","        learning_rate=learning_rate,\n","        loss=loss,\n","        random_state=42\n","    )\n","\n","    model.fit(train_interactions, epochs=epochs, verbose=False, sample_weight=train_weights)\n","    test_auc = auc_score(model, test_interactions).mean()\n","    return test_auc\n","\n","# Realizar búsqueda de hiperparámetros con Optuna\n","study = optuna.create_study(direction='maximize')\n","study.optimize(objective, n_trials=10)\n","\n","print(f\"Best trial AUC: {study.best_value:.4f}\")\n","print(f\"Best Params: {study.best_params}\")"],"metadata":{"id":"PpRIu0GNr-ZC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#######################################################################\n","#### 6 Generar recomendaciones con modelo LightFM #####################\n","#######################################################################\n","\n","def recommendation(model, data, original_user_id, conn, k):\n","    df_all = pd.read_sql(f\"SELECT * FROM ratings\", con)\n","    movie_ids_all = df_all['movieId'].unique()\n","\n","    # Usuario en ID interno\n","    uid_index = data.mapping()[0][original_user_id]\n","    item_ids = [value for key, value in data.mapping()[2].items()]\n","    scores = model.predict(uid_index, item_ids)\n","\n","    sorted_indices = np.argsort(-scores)\n","    top_items = [key for key, value in data.mapping()[2].items() if value in sorted_indices[:k]]\n","\n","    full_movies = pd.read_sql(\"SELECT DISTINCT movieId, title FROM full_ratings\", con)\n","    recommended = full_movies[full_movies['movieId'].isin(top_items)]\n","\n","    return recommended\n","\n","# Obtener recomendaciones para el usuario con ID = 1\n","recommendation(model, dataset_train, 1, con, 10)"],"metadata":{"id":"4ofGLemlr--A"},"execution_count":null,"outputs":[]}]}